<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Chat</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <script src="https://unpkg.com/@mlc-ai/web-llm"></script>
</head>
<body class="bg-gray-950 text-white min-h-screen flex flex-col">
  <header id="chatHeader" class="p-4 bg-gray-900 shadow text-lg font-bold">Chat</header>

  <main id="chatBox" class="flex-grow overflow-y-auto p-6 space-y-4"></main>

  <form id="chatForm" class="p-4 bg-gray-900 flex gap-2">
    <input id="userInput" type="text" placeholder="Type your message..."
      class="flex-grow p-2 rounded-lg bg-gray-800 border border-gray-700 focus:outline-none" />
    <button class="bg-blue-600 hover:bg-blue-500 px-4 py-2 rounded-lg font-medium">Send</button>
  </form>

  <script type="module">
    import { CreateMLCEngine } from "https://esm.run/@mlc-ai/web-llm";

    let persona = null;
    let messagesHistory = [];
    let engine = null;

    const chatBox = document.getElementById("chatBox");
    const chatHeader = document.getElementById("chatHeader");
    const chatForm = document.getElementById("chatForm");
    const userInput = document.getElementById("userInput");

    // Format text: Markdown-like + <think>
    function formatText(text) {
      // Replace <think>…</think> with italics
      const withThink = text.replace(/<think>(.*?)<\/think>/gs, "<i>$1</i>");
      // Basic markdown: **bold**, *italic*, `code`
      let md = withThink
        .replace(/\*\*(.*?)\*\*/g, "<b>$1</b>")
        .replace(/`(.*?)`/g, "<code>$1</code>");
      // handle *italic* last to avoid conflicts with bold
      md = md.replace(/\*(.*?)\*/g, "<i>$1</i>");
      // Convert line breaks to <br> for multi-paragraph RP
      md = md.replace(/\n/g, "<br>");
      return md;
    }

    function appendMessage(sender, text) {
      const msgDiv = document.createElement("div");
      msgDiv.className = sender === "user"
        ? "bg-blue-600 p-3 rounded-lg self-end max-w-lg ml-auto whitespace-pre-wrap"
        : "bg-gray-800 p-3 rounded-lg self-start max-w-lg whitespace-pre-wrap";
      msgDiv.innerHTML = formatText(text);
      chatBox.appendChild(msgDiv);
      chatBox.scrollTop = chatBox.scrollHeight;
    }

    // Persistence: load & save
    function saveHistory() {
      if (!persona) return;
      const key = "chat_history_" + persona.id;
      try {
        localStorage.setItem(key, JSON.stringify(messagesHistory));
      } catch (err) {
        console.warn("Failed to save history:", err);
      }
    }

    function loadHistory() {
      if (!persona) return;
      const key = "chat_history_" + persona.id;
      const json = localStorage.getItem(key);
      if (json) {
        try {
          const arr = JSON.parse(json);
          if (Array.isArray(arr)) {
            messagesHistory = arr;
            for (const msg of messagesHistory) {
              if (msg.role === "user") appendMessage("user", msg.content);
              else if (msg.role === "assistant") appendMessage("ai", msg.content);
            }
          }
        } catch (err) {
          console.warn("Invalid history JSON:", err);
        }
      }
    }

    // Load persona & system prompt
    async function loadPersona() {
      const params = new URLSearchParams(window.location.search);
      const personaId = params.get("persona");
      const res = await fetch("personas.json");
      const personas = await res.json();
      persona = personas.find(p => p.id === personaId);
      if (!persona) {
        alert("Persona not found");
        throw new Error("Persona not found");
      }
      document.title = persona.name + " – Chat";
      chatHeader.textContent = "Chat with " + persona.name;

      loadHistory();
      if (messagesHistory.length === 0) {
        messagesHistory.push({ role: "system", content: persona.system });
        appendMessage("ai", `You are now chatting with **${persona.name}**`);
      }
    }

    // Initialize model
    async function initEngine() {
      appendMessage("ai", "⏳ Loading model...");
      engine = await CreateMLCEngine("Llama-3.2-1B-Instruct-q4f16_1-MLC", {
        initProgressCallback: (p) => {
          console.debug("Load progress:", p);
        }
      });
      appendMessage("ai", "✅ Model loaded. You can start chatting!");
    }

    // Streaming RP reply
    async function aiReplyStream(userMsg) {
      messagesHistory.push({ role: "user", content: userMsg });

      const stream = await engine.chat.completions.create({
        messages: messagesHistory,
        temperature: 0.8,
        stream: true,
        max_tokens: 1024
      });

      let assistantDiv = null;
      let cumulated = "";

      for await (const chunk of stream) {
        const delta = chunk?.choices?.[0]?.delta?.content || "";
        cumulated += delta;

        if (!assistantDiv) {
          assistantDiv = document.createElement("div");
          assistantDiv.className = "bg-gray-800 p-3 rounded-lg self-start max-w-lg whitespace-pre-wrap";
          chatBox.appendChild(assistantDiv);
        }
        assistantDiv.innerHTML = formatText(cumulated);
        chatBox.scrollTop = chatBox.scrollHeight;
      }

      messagesHistory.push({ role: "assistant", content: cumulated });
      saveHistory();
    }

    // On form submit
    chatForm.addEventListener("submit", async (ev) => {
      ev.preventDefault();
      const txt = userInput.value.trim();
      if (!txt) return;
      appendMessage("user", txt);
      userInput.value = "";
      await aiReplyStream(txt);
    });

    // Boot sequence
    await loadPersona();
    await initEngine();
  </script>
</body>
</html>
